import streamlit as st
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from PIL import Image
import cv2
import matplotlib.pyplot as plt
import os

# === Variables globales pour le cache ===
converted_model_cache = None

# === Diagnostic des fichiers ===
files_to_check = [
    "skin_cancer_model.weights.h5",
    "skin_cancer_model.h5", 
    "skin_cancer_model.keras",
    "skin_cancer_model_savedmodel"
]

st.write("üîç **Fichiers de mod√®le disponibles:**")
for file in files_to_check:
    if os.path.exists(file):
        size_mb = os.path.getsize(file) / (1024 * 1024)
        st.write(f"‚úÖ {file} trouv√© ({size_mb:.1f} MB)")
    else:
        st.write(f"‚ùå {file} non trouv√©")

# === Fonction Grad-CAM optimis√©e pour Streamlit ===
def make_gradcam_for_streamlit(img_array, model, layer_search_name, pred_index=None):
    """
    Version Grad-CAM simplifi√©e pour les mod√®les d√©j√† fonctionnels
    """
    try:
        # SIMPLIFICATION MAJEURE : Plus besoin de conversion ou de cache complexe
        working_model = model
        
        # Trouver la couche convolutionnelle
        conv_layer = None
        for layer in working_model.layers:
            # On cherche un nom exact car les noms peuvent √™tre complexes
            if layer.name == layer_search_name:
                conv_layer = layer
                break
        
        if conv_layer is None:
            st.error(f"Couche '{layer_search_name}' introuvable. Couches disponibles: {[l.name for l in working_model.layers]}")
            return None
        
        # S'assurer que l'entr√©e est un tensor
        if not isinstance(img_array, tf.Tensor):
            img_array = tf.convert_to_tensor(img_array, dtype=tf.float32)
        
        # Cr√©er le mod√®le Grad-CAM avec un nom unique bas√© sur le timestamp
        import time
        unique_id = str(int(time.time() * 1000))[-6:]
        
        grad_model = tf.keras.models.Model(
            inputs=working_model.input,
            outputs=[conv_layer.output, working_model.output],
            name=f'gradcam_model_{unique_id}'
        )
        
        # Calcul des gradients
        with tf.GradientTape() as tape:
            tape.watch(img_array)
            conv_outputs, predictions = grad_model(img_array, training=False)
            
            if pred_index is None:
                pred_index = tf.argmax(predictions[0])
            
            class_channel = predictions[:, pred_index]
        
        # Obtenir les gradients
        grads = tape.gradient(class_channel, conv_outputs)
        
        if grads is None:
            st.error("Gradients None - couche non diff√©rentiable")
            return None
        
        # Calculer la carte de chaleur
        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        conv_outputs = conv_outputs[0]
        heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        
        # Normalisation
        heatmap = tf.maximum(heatmap, 0)
        max_val = tf.math.reduce_max(heatmap)
        
        if max_val > 1e-8:
            heatmap = heatmap / max_val
        else:
            heatmap = tf.ones_like(heatmap) * 0.5
        
        return heatmap.numpy()
        
    except Exception as e:
        st.error(f"‚ùå Erreur Grad-CAM: {e}")
        with st.expander("üîç D√©tails de l'erreur"):
            import traceback
            st.code(traceback.format_exc())
        return None

# === Diagnostic du mod√®le adapt√© ===
def diagnose_model_streamlit(model):
    """Diagnostic du mod√®le pour Streamlit (compatible avec wrapper)"""
    try:
        st.info("üîç Analyse du mod√®le...")
        
        # V√©rifier si c'est notre wrapper ou un mod√®le Keras normal
        if isinstance(model, SavedModelWrapper):
            st.info("üìã Mod√®le: SavedModel avec wrapper")
            st.warning("‚ö†Ô∏è Grad-CAM non disponible avec SavedModel")
            return []  # Pas de couches conv disponibles pour Grad-CAM
        
        # Mod√®le Keras normal
        model_type = type(model).__name__
        layer_count = len(model.layers)
        
        # Trouver les couches convolutionnelles
        conv_layers = []
        all_layers_info = []
        
        for i, layer in enumerate(model.layers):
            layer_type = type(layer).__name__
            layer_name = layer.name
            all_layers_info.append(f"{layer_name} ({layer_type})")
            
            # V√©rifier si c'est une vraie couche convolutionnelle
            if hasattr(layer, 'filters') and hasattr(layer, 'kernel_size'):
                conv_layers.append(layer.name)
        
        # Affichage des informations
        st.success(f"üìä Mod√®le: {model_type} avec {layer_count} couches")
        
        if conv_layers:
            st.success(f"üéØ Couches convolutionnelles: {conv_layers}")
        else:
            st.warning("‚ö†Ô∏è Aucune couche convolutionnelle d√©tect√©e")
        
        return conv_layers
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors du diagnostic: {e}")
        return []

# === WRAPPER POUR SAVEDMODEL ===
class SavedModelWrapper:
    """Wrapper pour utiliser un SavedModel comme un mod√®le Keras"""
    
    def __init__(self, savedmodel_path):
        self.model = tf.saved_model.load(savedmodel_path)
        self.serving_fn = self.model.signatures['serving_default']
        
        # Analyser la signature pour comprendre les entr√©es/sorties
        self.input_key = list(self.serving_fn.structured_input_signature[1].keys())[0]
        self.output_key = list(self.serving_fn.structured_outputs.keys())[0]
        
        st.info(f"üìã Input key: {self.input_key}")
        st.info(f"üìã Output key: {self.output_key}")
    
    def predict(self, x, verbose=0):
        """M√©thode predict compatible avec Keras"""
        # Convertir l'entr√©e au bon format
        if isinstance(x, np.ndarray):
            x = tf.convert_to_tensor(x, dtype=tf.float32)
        
        # Faire la pr√©diction avec la signature
        input_dict = {self.input_key: x}
        output = self.serving_fn(**input_dict)
        
        # Extraire la sortie
        result = output[self.output_key].numpy()
        return result
    
    @property
    def layers(self):
        """Propri√©t√© layers fictive pour compatibilit√©"""
        return []

# === NOUVELLE FONCTION DE CHARGEMENT CORRIG√âE ===
@st.cache_resource
def load_skin_cancer_model_robust():
    """
    Charge le mod√®le en essayant plusieurs m√©thodes dans l'ordre de pr√©f√©rence
    """
    
    # M√âTHODE 1: SavedModel avec wrapper (PRIORIT√â car c'est ce qui fonctionne)
    if os.path.isdir("skin_cancer_model_savedmodel"):
        try:
            # V√©rifier que le dossier contient bien des fichiers
            savedmodel_files = []
            for root, dirs, files in os.walk("skin_cancer_model_savedmodel"):
                savedmodel_files.extend(files)
            
            if len(savedmodel_files) > 0:
                st.info(f"üîÑ Chargement du SavedModel... ({len(savedmodel_files)} fichiers trouv√©s)")
                
                # D'abord, essayer le chargement Keras normal
                try:
                    model = tf.keras.models.load_model("skin_cancer_model_savedmodel")
                    if hasattr(model, 'predict') and hasattr(model, 'layers'):
                        st.success("‚úÖ SavedModel Keras charg√© avec succ√®s !")
                        return model
                except:
                    pass
                
                # Si √ßa ne marche pas, utiliser notre wrapper
                st.info("üîÑ Utilisation du wrapper SavedModel...")
                wrapped_model = SavedModelWrapper("skin_cancer_model_savedmodel")
                st.success("‚úÖ SavedModel avec wrapper charg√© avec succ√®s !")
                return wrapped_model
            else:
                st.warning("‚ö†Ô∏è Dossier SavedModel vide")
                
        except Exception as e:
            st.warning(f"‚ùå √âchec SavedModel: {str(e)[:100]}...")
            with st.expander("üîç D√©tails erreur SavedModel"):
                st.code(str(e))
    
    # M√âTHODE 2: Essayer .h5 avec des options compatibilit√©
    if os.path.exists("skin_cancer_model.h5"):
        try:
            st.info("üîÑ Chargement du mod√®le .h5 (mode compatibilit√©)...")
            model = tf.keras.models.load_model("skin_cancer_model.h5", compile=False)
            st.success("‚úÖ Mod√®le .h5 charg√© avec succ√®s !")
            return model
        except Exception as e:
            st.warning(f"‚ùå √âchec .h5: {str(e)[:100]}...")
    
    # M√âTHODE 3: Essayer .keras avec des options compatibilit√©
    if os.path.exists("skin_cancer_model.keras"):
        try:
            st.info("üîÑ Chargement du mod√®le .keras (mode compatibilit√©)...")
            model = tf.keras.models.load_model("skin_cancer_model.keras", compile=False)
            st.success("‚úÖ Mod√®le .keras charg√© avec succ√®s !")
            return model
        except Exception as e:
            st.warning(f"‚ùå √âchec .keras: {str(e)[:100]}...")
    
    # Si aucune m√©thode n'a fonctionn√©
    st.error("‚ùå Toutes les m√©thodes de chargement ont √©chou√©")
    st.info("üí° **Solutions:**")
    st.write("1. Le SavedModel semble √™tre votre meilleur option")
    st.write("2. V√©rifiez votre version de TensorFlow")
    st.write("3. Essayez: `pip install tensorflow==2.15.0`")
    st.write("4. Ou r√©g√©n√©rez le mod√®le avec votre version actuelle")
    
    raise Exception("Impossible de charger le mod√®le avec toutes les m√©thodes disponibles")

# === Noms et descriptions des classes ===
class_names = {
    'akiec': "Carcinome intra√©pith√©lial actinique",
    'bcc': "Carcinome basocellulaire", 
    'bkl': "K√©ratose b√©nigne",
    'df': "Dermatofibrome",
    'mel': "M√©lanome",
    'nv': "Grain de beaut√© b√©nin",
    'vasc': "L√©sion vasculaire"
}

class_descriptions = {
    'akiec': "L√©sion pr√©canc√©reuse (maligne)",
    'bcc': "Cancer de la peau √† croissance lente",
    'bkl': "L√©sion non canc√©reuse de la peau", 
    'df': "Tumeur cutan√©e b√©nigne rare",
    'mel': "Cancer de la peau dangereux",
    'nv': "Grain de beaut√© fr√©quent, non canc√©reux",
    'vasc': "L√©sion des vaisseaux sanguins b√©nigne"
}

# === Interface Streamlit ===
st.title("üåø D√©tection de grains de beaut√© canc√©rig√®nes")
st.markdown("Uploadez une image et le mod√®le pr√©dit sa classe avec visualisation Grad-CAM.")

# === Chargement du mod√®le ===
try:
    model = load_skin_cancer_model_robust()
    
    # Diagnostic du mod√®le
    conv_layers = diagnose_model_streamlit(model)
    
except Exception as e:
    st.error(f"‚ùå Impossible de charger le mod√®le: {e}")
    st.info("üí° **Solutions possibles:**")
    st.write("- V√©rifiez que vos fichiers de mod√®le (.h5, .keras) ne sont pas corrompus")
    st.write("- R√©entra√Ænez votre mod√®le si n√©cessaire")
    st.write("- Assurez-vous d'avoir sauvegard√© le mod√®le complet (pas seulement les poids)")
    st.stop()

# === Interface utilisateur ===
uploaded_file = st.file_uploader("Choisissez une image JPG ou PNG", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    try:
        # Pr√©processing de l'image
        img = Image.open(uploaded_file).convert('RGB').resize((64, 64))
        st.image(img, caption="Image charg√©e", use_column_width=False)
        
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        # Pr√©diction
        with st.spinner("üîÆ Analyse en cours..."):
            prediction = model.predict(img_array, verbose=0)
            
            predicted_index = np.argmax(prediction)
            predicted_key = list(class_names.keys())[predicted_index]
            predicted_label = class_names[predicted_key]
            predicted_confidence = prediction[0][predicted_index] * 100
        
        # Affichage des r√©sultats
        col1, col2 = st.columns(2)
        
        with col1:
            # R√©sultats de pr√©diction
            if prediction.max() < 0.4:
                st.warning("‚ùå Image tr√®s diff√©rente des exemples d'entra√Ænement")
            else:
                st.success(f"‚úÖ Classe pr√©dite: **{predicted_label}**")
                st.info(f"‚ÑπÔ∏è {class_descriptions[predicted_key]}")
            
            st.info(f"üéØ Confiance: {predicted_confidence:.2f}%")
            
            if predicted_key in ['mel', 'akiec', 'bcc']:
                st.error("‚ö†Ô∏è Type potentiellement **dangereux** - Consultez un dermatologue")
            
            # Graphique camembert
            st.subheader("üìä Distribution des probabilit√©s")
            labels = list(class_names.values())
            sizes = [prediction[0][i] * 100 for i in range(len(labels))]
            colors = ["#ffe6f0", "#ffcce0", "#ffb3d1", "#ff99c2", "#ff80b3", "#ff66a3", "#ff4d94"]
            
            fig, ax = plt.subplots(figsize=(8, 8))
            ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, 
                   colors=colors, textprops={'fontsize': 9})
            ax.axis('equal')
            st.pyplot(fig)
        
        with col2:
            st.subheader("üß† Analyse Grad-CAM")
            if conv_layers:
                layer_to_use = conv_layers[-1] 
                
                st.info(f"üß† Utilisation de la couche : **{layer_to_use}**")
                
                # G√©n√©rer la heatmap
                with st.spinner("üî• G√©n√©ration de la carte de chaleur..."):
                    test_input = tf.convert_to_tensor(img_array, dtype=tf.float32)
                    heatmap = make_gradcam_for_streamlit(test_input, model, layer_to_use, predicted_index)
                
                if heatmap is not None:
                    try:
                        # Superposer sur l'image originale
                        img_rgb = np.array(img)
                        heatmap_resized = cv2.resize(heatmap, (img_rgb.shape[1], img_rgb.shape[0]))
                        heatmap_colored = np.uint8(255 * heatmap_resized)
                        heatmap_colored = cv2.applyColorMap(heatmap_colored, cv2.COLORMAP_JET)
                        
                        # Fusion des images
                        superimposed_img = cv2.addWeighted(img_rgb, 0.6, heatmap_colored, 0.4, 0)
                        
                        st.image(superimposed_img, 
                                caption=f"üéØ Zones d'attention du mod√®le", 
                                use_column_width=True)
                        
                        st.success("üî• Rouge = zones importantes pour la d√©cision")
                        st.info(f"üì± Couche utilis√©e: {layer_to_use}")
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de la visualisation: {e}")
                else:
                    st.error("‚ùå Impossible de g√©n√©rer la carte Grad-CAM")
            elif isinstance(model, SavedModelWrapper):
                st.info("‚ÑπÔ∏è **Grad-CAM non disponible avec SavedModel**")
                st.write("Le mod√®le fonctionne mais les couches internes ne sont pas accessibles.")
                st.write("Pour avoir Grad-CAM, utilisez un mod√®le .h5 ou .keras.")
                
                # Afficher quand m√™me l'image originale
                st.image(img, caption="üñºÔ∏è Image analys√©e", use_column_width=True)
            else:
                st.warning("‚ö†Ô∏è Pas de couches convolutionnelles d√©tect√©es")
                st.info("Le mod√®le ne semble pas compatible avec Grad-CAM")
                
                # Afficher quand m√™me l'image originale
                st.image(img, caption="üñºÔ∏è Image analys√©e", use_column_width=True)
                
    except Exception as e:
        st.error(f"‚ùå Erreur lors du traitement: {e}")
        with st.expander("üîç D√©tails de l'erreur"):
            import traceback
            st.code(traceback.format_exc())

# === Informations ===
st.markdown("---")
st.subheader("‚ÑπÔ∏è √Ä propos")
st.markdown("""
Cette application utilise un mod√®le de deep learning pour classifier les l√©sions cutan√©es:

**Classes d√©tect√©es:**
- **M√©lanome (mel)** ‚ö†Ô∏è : Cancer dangereux
- **Carcinome basocellulaire (bcc)** ‚ö†Ô∏è : Cancer commun 
- **Carcinome actinique (akiec)** ‚ö†Ô∏è : L√©sion pr√©canc√©reuse
- **Grain de beaut√© b√©nin (nv)** ‚úÖ : Non canc√©reux
- **K√©ratose b√©nigne (bkl)** ‚úÖ : L√©sion b√©nigne
- **Dermatofibrome (df)** ‚úÖ : Tumeur b√©nigne
- **L√©sion vasculaire (vasc)** ‚úÖ : Anomalie b√©nigne

**Grad-CAM** montre les zones sur lesquelles le mod√®le se concentre pour prendre sa d√©cision.
""")

st.error("‚ö†Ô∏è **AVERTISSEMENT M√âDICAL**: Application √† but √©ducatif uniquement. Consultez un professionnel pour un diagnostic m√©dical.")